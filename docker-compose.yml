services:
  postgres:
    image: postgres:15
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-airflow}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-airflow}
      POSTGRES_DB: ${POSTGRES_DB:-airflow}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./src/config/postgres/10_create_rpa_db.sql:/docker-entrypoint-initdb.d/10_create_rpa_db.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-airflow} || pg_isready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  airflow-webserver:
    build: ./airflow
    user: "0:0"
    environment:
      AZURE_KEYVAULT_URL: ${AZURE_KEYVAULT_URL}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_CORE_FERNET_KEY}
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/src/dags
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
      AIRFLOW_CONN_PUBLISH_API: ${AIRFLOW_CONN_PUBLISH_API:-http://rpa-api:3000}
      AIRFLOW__SECRETS__BACKEND: airflow.secrets.environment_variables.EnvironmentVariablesBackend
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: True
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      AIRFLOW_WWW_USER_USERNAME: ${AIRFLOW_WWW_USER_USERNAME}
      AIRFLOW_WWW_USER_PASSWORD: ${AIRFLOW_WWW_USER_PASSWORD}
      AIRFLOW__CORE__LOAD_EXAMPLES: False
      AIRFLOW__CORE__DEFAULT_UI_TIMEZONE: UTC
      AIRFLOW__WEBSERVER__DEFAULT_UI_TIMEZONE: UTC
      AIRFLOW__WEBSERVER__WEB_SERVER_PORT: 8080
      AIRFLOW__WEBSERVER__BASE_URL: http://localhost:8080
      AIRFLOW__WEBSERVER__WEB_SERVER_HOST: 0.0.0.0
      AIRFLOW__CORE__PARALLELISM: 1
      AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG: 1
      AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG: 1
      AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT: 30.0
      AIRFLOW__CORE__DAG_FILE_PROCESSOR_TIMEOUT: 50
      AIRFLOW__CORE__TASK_RUNNER: StandardTaskRunner
      AIRFLOW__CORE__DONOT_PICKLE: False
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: True
      AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS: True
      AIRFLOW__CORE__LOAD_DEFAULT_VARIABLES: True
      AIRFLOW__CORE__CHECK_SLAS: True
      AIRFLOW__CORE__ALWAYS_EMAIL_ON_RETRY: False
      AIRFLOW__CORE__ALWAYS_EMAIL_ON_FAILURE: False
      AIRFLOW__CORE__DEFAULT_EMAIL_ON_RETRY: False
      AIRFLOW__CORE__DEFAULT_EMAIL_ON_FAILURE: False
      AIRFLOW__CORE__DEFAULT_EMAIL: admin@example.com
      AIRFLOW__CORE__SMTP_HOST: localhost
      AIRFLOW__CORE__SMTP_STARTTLS: True
      AIRFLOW__CORE__SMTP_SSL: False
      AIRFLOW__CORE__SMTP_USER: ""
      AIRFLOW__CORE__SMTP_PASSWORD: ""
      AIRFLOW__CORE__SMTP_PORT: 587
      AIRFLOW__CORE__SMTP_MAIL_FROM: admin@example.com
      AIRFLOW__CORE__HIDE_SENSITIVE_VAR_CONN_FIELDS: True
      AIRFLOW__CORE__SENSITIVE_VAR_CONN_FIELD_NAMES: password,passwd,secret,api_key,apikey,access_token
      AIRFLOW__CORE__SENSITIVE_VAR_CONN_FIELD_SECTION: password,passwd,secret,api_key,apikey,access_token
    entrypoint: /start-with-api.sh
    ports:
      - "8080:8080"
      - "8000:8000"
    volumes:
      - ./airflow/src/dags:/opt/airflow/src/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/src/services:/opt/airflow/src/services
      - ./airflow/src/api:/opt/airflow/src/api
      - ./airflow/src/operators:/opt/airflow/src/operators
      - ./airflow/src/libs:/opt/airflow/src/libs
      - ./airflow/src/tasks:/opt/airflow/src/tasks
      - ./shared/data:/opt/airflow/data
      - ./shared/downloads:/opt/airflow/downloads
    depends_on:
      postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped

  airflow-scheduler:
    build: ./airflow
    user: "0:0"
    environment:
      AZURE_KEYVAULT_URL: ${AZURE_KEYVAULT_URL}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_CORE_FERNET_KEY}
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/src/dags
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
      AIRFLOW_CONN_PUBLISH_API: ${AIRFLOW_CONN_PUBLISH_API:-http://rpa-api:3000}
      AIRFLOW__SECRETS__BACKEND: airflow.secrets.environment_variables.EnvironmentVariablesBackend
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: True
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      AIRFLOW__CORE__LOAD_EXAMPLES: False
      AIRFLOW__CORE__DEFAULT_UI_TIMEZONE: UTC
      AIRFLOW__WEBSERVER__DEFAULT_UI_TIMEZONE: UTC
      AIRFLOW__WEBSERVER__WEB_SERVER_PORT: 8080
      AIRFLOW__WEBSERVER__BASE_URL: http://localhost:8080
      AIRFLOW__WEBSERVER__WEB_SERVER_HOST: 0.0.0.0
      AIRFLOW__CORE__PARALLELISM: 1
      AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG: 1
      AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG: 1
      AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT: 30.0
      AIRFLOW__CORE__DAG_FILE_PROCESSOR_TIMEOUT: 50
      AIRFLOW__CORE__TASK_RUNNER: StandardTaskRunner
      AIRFLOW__CORE__DONOT_PICKLE: False
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: True
      AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS: True
      AIRFLOW__CORE__LOAD_DEFAULT_VARIABLES: True
      AIRFLOW__CORE__CHECK_SLAS: True
      AIRFLOW__CORE__ALWAYS_EMAIL_ON_RETRY: False
      AIRFLOW__CORE__ALWAYS_EMAIL_ON_FAILURE: False
      AIRFLOW__CORE__DEFAULT_EMAIL_ON_RETRY: False
      AIRFLOW__CORE__DEFAULT_EMAIL_ON_FAILURE: False
      AIRFLOW__CORE__DEFAULT_EMAIL: admin@example.com
      AIRFLOW__CORE__SMTP_HOST: localhost
      AIRFLOW__CORE__SMTP_STARTTLS: True
      AIRFLOW__CORE__SMTP_SSL: False
      AIRFLOW__CORE__SMTP_USER: ""
      AIRFLOW__CORE__SMTP_PASSWORD: ""
      AIRFLOW__CORE__SMTP_PORT: 587
      AIRFLOW__CORE__SMTP_MAIL_FROM: admin@example.com
      AIRFLOW__CORE__HIDE_SENSITIVE_VAR_CONN_FIELDS: True
      AIRFLOW__CORE__SENSITIVE_VAR_CONN_FIELD_NAMES: password,passwd,secret,api_key,apikey,access_token
      AIRFLOW__CORE__SENSITIVE_VAR_CONN_FIELD_SECTION: password,passwd,secret,api_key,apikey,access_token
    command: scheduler
    volumes:
      - ./airflow/src/dags:/opt/airflow/src/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/src/services:/opt/airflow/src/services
      - ./airflow/src/api:/opt/airflow/src/api
      - ./airflow/src/operators:/opt/airflow/src/operators
      - ./airflow/src/libs:/opt/airflow/src/libs
      - ./airflow/src/tasks:/opt/airflow/src/tasks
      - ./shared/data:/opt/airflow/data
      - ./shared/downloads:/opt/airflow/downloads
    depends_on:
      postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    restart: unless-stopped

  airflow-init:
    build: ./airflow
    user: "0:0"
    environment:
      AZURE_KEYVAULT_URL: ${AZURE_KEYVAULT_URL}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_CORE_FERNET_KEY}
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/src/dags
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
      AIRFLOW_CONN_PUBLISH_API: ${AIRFLOW_CONN_PUBLISH_API:-http://rpa-api:3000}
      AIRFLOW_API_BASE_URL: ${AIRFLOW_API_BASE_URL:-http://airflow-webserver:8000}
      AIRFLOW__SECRETS__BACKEND: airflow.secrets.environment_variables.EnvironmentVariablesBackend
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: True
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      AIRFLOW__CORE__LOAD_EXAMPLES: False
      AIRFLOW__CORE__DEFAULT_UI_TIMEZONE: UTC
      AIRFLOW__WEBSERVER__DEFAULT_UI_TIMEZONE: UTC
      AIRFLOW__WEBSERVER__WEB_SERVER_PORT: 8080
      AIRFLOW__WEBSERVER__BASE_URL: http://localhost:8080
      AIRFLOW__WEBSERVER__WEB_SERVER_HOST: 0.0.0.0
      AIRFLOW__CORE__PARALLELISM: 1
      AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG: 1
      AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG: 1
      AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT: 30.0
      AIRFLOW__CORE__DAG_FILE_PROCESSOR_TIMEOUT: 50
      AIRFLOW__CORE__TASK_RUNNER: StandardTaskRunner
      AIRFLOW__CORE__DONOT_PICKLE: False
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: True
      AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS: True
      AIRFLOW__CORE__LOAD_DEFAULT_VARIABLES: True
      AIRFLOW__CORE__CHECK_SLAS: True
      AIRFLOW__CORE__ALWAYS_EMAIL_ON_RETRY: False
      AIRFLOW__CORE__ALWAYS_EMAIL_ON_FAILURE: False
      AIRFLOW__CORE__DEFAULT_EMAIL_ON_RETRY: False
      AIRFLOW__CORE__DEFAULT_EMAIL_ON_FAILURE: False
      AIRFLOW__CORE__DEFAULT_EMAIL: admin@example.com
      AIRFLOW__CORE__SMTP_HOST: localhost
      AIRFLOW__CORE__SMTP_STARTTLS: True
      AIRFLOW__CORE__SMTP_SSL: False
      AIRFLOW__CORE__SMTP_USER: ""
      AIRFLOW__CORE__SMTP_PASSWORD: ""
      AIRFLOW__CORE__SMTP_PORT: 587
      AIRFLOW__CORE__SMTP_MAIL_FROM: admin@example.com
      AIRFLOW__CORE__HIDE_SENSITIVE_VAR_CONN_FIELDS: True
      AIRFLOW__CORE__SENSITIVE_VAR_CONN_FIELD_NAMES: password,passwd,secret,api_key,apikey,access_token
      AIRFLOW__CORE__SENSITIVE_VAR_CONN_FIELD_SECTION: password,passwd,secret,api_key,apikey,access_token
    entrypoint: /bin/bash
    command:
      - -c
      - |
        set -e
        airflow db migrate
        airflow users create \
          --username "${AIRFLOW_WWW_USER_USERNAME:-admin}" \
          --password "${AIRFLOW_WWW_USER_PASSWORD:-admin}" \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com || true
        # Set required Airflow Variables
        airflow variables set ECARGO_XLSX_PATH /opt/airflow/data/Controle_Unilever_Personalizado.xlsx || true
        airflow variables set AIRFLOW_API_BASE_URL ${AIRFLOW_API_BASE_URL:-http://airflow-webserver:8000} || true
        # Create required Airflow Connections
        airflow connections delete rpa_api || true
        airflow connections add rpa_api \
          --conn-type http \
          --conn-host rpa-api \
          --conn-port 3000 || true
    volumes:
      - ./airflow/src/dags:/opt/airflow/src/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/src/services:/opt/airflow/src/services
      - ./airflow/src/api:/opt/airflow/src/api
      - ./airflow/src/operators:/opt/airflow/src/operators
      - ./airflow/src/libs:/opt/airflow/src/libs
      - ./airflow/src/tasks:/opt/airflow/src/tasks
      - ./shared/data:/opt/airflow/data
      - ./shared/downloads:/opt/airflow/downloads
    depends_on:
      postgres:
        condition: service_healthy

  rpa-db-init:
    image: python:3.11-slim
    entrypoint: /bin/bash
    command:
      - -c
      - |
        set -e
        pip install --quiet --no-cache-dir alembic psycopg2-binary python-dotenv
        cd /app/database
        alembic upgrade head
    environment:
      RPA_DB_HOST: ${RPA_DB_HOST:-postgres}
      RPA_DB_PORT: ${RPA_DB_PORT:-5432}
      RPA_DB_USER: ${RPA_DB_USER:-airflow}
      RPA_DB_PASSWORD: ${RPA_DB_PASSWORD:-airflow}
      RPA_DB_NAME: ${RPA_DB_NAME:-rpa_db}
    volumes:
      - ./src:/app
    working_dir: /app/database
    depends_on:
      postgres:
        condition: service_healthy
    restart: "no"

  rpa-api:
    build: ./rpa-api
    ports:
      - "${RPA_API_PORT:-3000}:3000"
    environment:
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: ${RABBITMQ_PORT:-5672}
      RABBITMQ_VHOST: ${RABBITMQ_DEFAULT_VHOST:-/}
      RABBITMQ_USER: ${RABBITMQ_DEFAULT_USER:-admin}
      RABBITMQ_PASSWORD: ${RABBITMQ_DEFAULT_PASS:-admin}
      RABBITMQ_EXCHANGE: ${RABBITMQ_EXCHANGE:-}
      RABBITMQ_ROBOT_OPERATOR_QUEUE: ${RABBITMQ_ROBOT_OPERATOR_QUEUE}
      RPA_DB_HOST: ${RPA_DB_HOST:-postgres}
      RPA_DB_PORT: ${RPA_DB_PORT:-5432}
      RPA_DB_USER: ${RPA_DB_USER:-airflow}
      RPA_DB_PASSWORD: ${RPA_DB_PASSWORD:-airflow}
      RPA_DB_NAME: ${RPA_DB_NAME:-rpa_db}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_MODEL_NAME: ${OPENAI_MODEL_NAME:-gpt-4o-mini}
    volumes:
      - ./shared/data:/opt/airflow/data
      - ./shared/downloads:/opt/airflow/downloads
    depends_on:
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      rpa-db-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/docs"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped

  rabbitmq:
    image: rabbitmq:3.13-management
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      RABBITMQ_LOAD_DEFINITIONS: /etc/rabbitmq/definitions.json
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_DEFAULT_USER:-admin}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_DEFAULT_PASS:-admin}
      RABBITMQ_DEFAULT_VHOST: /
    volumes:
      - ./src/config/rabbitmq/definitions.json:/etc/rabbitmq/definitions.json:ro
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped

volumes:
  postgres_data:
